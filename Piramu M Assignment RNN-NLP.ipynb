{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGtH5QR6MSv2VSFBhNYUgp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Piramu-Mahalingam/DS-Course-Assignment-1/blob/main/Piramu%20M%20Assignment%20RNN-NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2p22FVp3NsM"
      },
      "outputs": [],
      "source": [
        "#Piramu M Assignment NLP-RNN\n",
        "#a)\tExplain the architecture of LSTM and GRU in detail. What were the shortcomings of RNN that were resolved by LSTM and GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Background: RNN and its Shortcomings\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are designed to handle sequential data by maintaining a hidden state that captures information from previous time steps.\n",
        "\n",
        "Equation (vanilla RNN):![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "SPHmpz5R3cqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shortcomings of RNNs:\n",
        "\n",
        "Vanishing Gradient Problem – When training with backpropagation through time (BPTT), gradients shrink exponentially, making it hard to learn long-term dependencies.\n",
        "\n",
        "Exploding Gradient Problem – Sometimes gradients blow up, causing unstable training.\n",
        "\n",
        "Short-term Memory – RNNs mostly capture short dependencies but fail for long sequences (e.g., remembering context 50+ steps earlier).\n",
        "\n",
        "Slow Training – Difficulty in optimization due to gradient issues."
      ],
      "metadata": {
        "id": "8hEemSe44jQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Architecture (Long Short-Term Memory)\n",
        "\n",
        "An LSTM cell introduces a cell state and three gates to regulate information.\n",
        "\n",
        "Key Components:\n",
        "\n",
        "Cell State (Ct) Acts like a conveyor belt, carrying long-term information with minimal modification.\n",
        "\n",
        "Hidden State (ht) Used for current step output.\n",
        "\n",
        "Gates (sigmoid layers that output 0–1, controlling information flow):\n",
        "\n",
        "Forget Gate (ft) → Decides what to discard.\n",
        "\n",
        "Input Gate (it) → Decides what new info to store.\n",
        "\n",
        "Output Gate (ot) → Decides what to output."
      ],
      "metadata": {
        "id": "8LJwUg2b4lpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "low:\n",
        "\n",
        "Forget Gate: drops irrelevant info.\n",
        "\n",
        "Input Gate + Candidate: adds new relevant info.\n",
        "\n",
        "Output Gate: decides the final output.\n",
        "\n",
        "This structure preserves long-term dependencies and avoids vanishing gradients."
      ],
      "metadata": {
        "id": "9HXWfpd45Edc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU Architecture (Gated Recurrent Unit)\n",
        "\n",
        "GRU is a simplified version of LSTM – it merges cell state & hidden state into one (ht) and uses only two gates.\n",
        "\n",
        "Key Components:\n",
        "\n",
        "Update Gate (zt) – Combines role of input + forget gate.\n",
        "\n",
        "Reset Gate (rt) – Decides how much past info to forget."
      ],
      "metadata": {
        "id": "1U_OIDtL5JKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "low:\n",
        "\n",
        "Reset Gate: decides how much past to ignore.\n",
        "\n",
        "Update Gate: decides how much of new vs old info to keep.\n",
        "\n",
        "GRU is computationally lighter and trains faster than LSTM while still solving RNN shortcomings."
      ],
      "metadata": {
        "id": "hqaBOaSC5YUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#b)\tUse the emotions detection dataset from below Kaggle link and create an end-to-end project on Jupyter/Colab to predict the person’s emotions.\n",
        "\n",
        "https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp/data\n"
      ],
      "metadata": {
        "id": "ObUEl2oZ5dZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final quick evaluation without gridsearch to ensure completion within time\n",
        "import pandas as pd, re, warnings, os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = pd.read_csv(\"/mnt/data/extracted_dataset/test.txt\", sep=';', header=None, names=['text','label'], encoding='utf-8', engine='python')\n",
        "STOPWORDS = set(\"\"\"a about above after again against all am an and any are aren't as at be because been before being below between both but by can't cannot could couldn't did didn't do does doesn't doing don't down during each few for from further had hadn't has hasn't have haven't having he he'd he'll he's her here here's hers herself him himself his how how's i i'd i'll i'm i've if in into is isn't it it's its itself let's me more most mustn't my myself no nor not of off on once only or other ought our ours ourselves out over own same shan't she she'd she'll she's should shouldn't so some such than that that's the their theirs them themselves then there there's these they they'd they'll they're they've this those through to too under until up very was wasn't we we'd we'll we're we've were weren't what what's when when's where where's which while who who's whom why why's with won't would wouldn't you you'd you'll you're you've your yours yourself yourselves\"\"\".split())\n",
        "\n",
        "def prep(s):\n",
        "    s = str(s).lower()\n",
        "    s = re.sub(r'http\\S+',' ', s)\n",
        "    s = re.sub(r'@\\w+',' ', s)\n",
        "    s = re.sub(r'[^a-z\\s]',' ', s)\n",
        "    tokens = [t for t in re.split(r'\\s+', s) if t and t not in STOPWORDS and len(t)>1]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['clean'] = df['text'].map(prep)\n",
        "le = LabelEncoder(); df['label_enc'] = le.fit_transform(df['label'])\n",
        "X = df['clean']; y = df['label_enc']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# features (smaller)\n",
        "tfv = TfidfVectorizer(max_features=1500, ngram_range=(1,2)); cv = CountVectorizer(max_features=1500, ngram_range=(1,2))\n",
        "X_train_tfidf = tfv.fit_transform(X_train); X_test_tfidf = tfv.transform(X_test)\n",
        "X_train_bow = cv.fit_transform(X_train); X_test_bow = cv.transform(X_test)\n",
        "svd = TruncatedSVD(n_components=30, random_state=42)\n",
        "X_train_w2v = svd.fit_transform(X_train_tfidf); X_test_w2v = svd.transform(X_test_tfidf)\n",
        "\n",
        "# classifiers with chosen hyperparams\n",
        "classifiers = {\n",
        "    \"LogReg\": LogisticRegression(C=1, max_iter=1000, solver='liblinear', random_state=42),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(max_depth=20, min_samples_split=5, random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=50, max_depth=20, n_jobs=1, random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "for feat_name, (Xtr, Xte) in [(\"TF-IDF\",(X_train_tfidf, X_test_tfidf)), (\"BOW\",(X_train_bow, X_test_bow)), (\"Dense-SVD\",(X_train_w2v, X_test_w2v))]:\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(Xtr, y_train)\n",
        "        preds = clf.predict(Xte)\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        prec = precision_score(y_test, preds, average='macro', zero_division=0)\n",
        "        rec = recall_score(y_test, preds, average='macro', zero_division=0)\n",
        "        f1 = f1_score(y_test, preds, average='macro', zero_division=0)\n",
        "        results.append({\"model\":name, \"features\":feat_name, \"accuracy\":acc, \"precision\":prec, \"recall\":rec, \"f1\":f1})\n",
        "\n",
        "res_df = pd.DataFrame(results).sort_values('f1', ascending=False).reset_index(drop=True)\n",
        "res_df.to_csv(\"/mnt/data/model_comparison_results_quick.csv\", index=False)\n",
        "display(res_df)\n",
        "print(\"Saved quick results to /mnt/data/model_comparison_results_quick.csv\")\n",
        "print(\"Best model by F1:\", res_df.iloc[0].to_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "sHLMLkzE5lLF",
        "outputId": "47498f27-01d3-4bcb-cf25-e3a76b67c0e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/mnt/data/extracted_dataset/test.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4067877779.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/data/extracted_dataset/test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mSTOPWORDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\"a about above after again against all am an and any are aren't as at be because been before being below between both but by can't cannot could couldn't did didn't do does doesn't doing don't down during each few for from further had hadn't has hasn't have haven't having he he'd he'll he's her here here's hers herself him himself his how how's i i'd i'll i'm i've if in into is isn't it it's its itself let's me more most mustn't my myself no nor not of off on once only or other ought our ours ourselves out over own same shan't she she'd she'll she's should shouldn't so some such than that that's the their theirs them themselves then there there's these they they'd they'll they're they've this those through to too under until up very was wasn't we we'd we'll we're we've were weren't what what's when when's where where's which while who who's whom why why's with won't would wouldn't you you'd you'll you're you've your yours yourself yourselves\"\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/extracted_dataset/test.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_WT4s0rX4qjO"
      }
    }
  ]
}