{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYqD5pMEA5qcRfSpmBTj2o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Piramu-Mahalingam/DS-Course-Assignment-1/blob/main/Piramu%20M%20Assignment%20RNN-NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2p22FVp3NsM"
      },
      "outputs": [],
      "source": [
        "#Piramu M Assignment NLP-RNN\n",
        "#a)\tExplain the architecture of LSTM and GRU in detail. What were the shortcomings of RNN that were resolved by LSTM and GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Background: RNN and its Shortcomings\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are designed to handle sequential data by maintaining a hidden state that captures information from previous time steps.\n",
        "\n",
        "Equation (vanilla RNN):![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "SPHmpz5R3cqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shortcomings of RNNs:\n",
        "\n",
        "Vanishing Gradient Problem – When training with backpropagation through time (BPTT), gradients shrink exponentially, making it hard to learn long-term dependencies.\n",
        "\n",
        "Exploding Gradient Problem – Sometimes gradients blow up, causing unstable training.\n",
        "\n",
        "Short-term Memory – RNNs mostly capture short dependencies but fail for long sequences (e.g., remembering context 50+ steps earlier).\n",
        "\n",
        "Slow Training – Difficulty in optimization due to gradient issues."
      ],
      "metadata": {
        "id": "8hEemSe44jQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Architecture (Long Short-Term Memory)\n",
        "\n",
        "An LSTM cell introduces a cell state and three gates to regulate information.\n",
        "\n",
        "Key Components:\n",
        "\n",
        "Cell State (Ct) Acts like a conveyor belt, carrying long-term information with minimal modification.\n",
        "\n",
        "Hidden State (ht) Used for current step output.\n",
        "\n",
        "Gates (sigmoid layers that output 0–1, controlling information flow):\n",
        "\n",
        "Forget Gate (ft) → Decides what to discard.\n",
        "\n",
        "Input Gate (it) → Decides what new info to store.\n",
        "\n",
        "Output Gate (ot) → Decides what to output."
      ],
      "metadata": {
        "id": "8LJwUg2b4lpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "low:\n",
        "\n",
        "Forget Gate: drops irrelevant info.\n",
        "\n",
        "Input Gate + Candidate: adds new relevant info.\n",
        "\n",
        "Output Gate: decides the final output.\n",
        "\n",
        "This structure preserves long-term dependencies and avoids vanishing gradients."
      ],
      "metadata": {
        "id": "9HXWfpd45Edc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU Architecture (Gated Recurrent Unit)\n",
        "\n",
        "GRU is a simplified version of LSTM – it merges cell state & hidden state into one (ht) and uses only two gates.\n",
        "\n",
        "Key Components:\n",
        "\n",
        "Update Gate (zt) – Combines role of input + forget gate.\n",
        "\n",
        "Reset Gate (rt) – Decides how much past info to forget."
      ],
      "metadata": {
        "id": "1U_OIDtL5JKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "low:\n",
        "\n",
        "Reset Gate: decides how much past to ignore.\n",
        "\n",
        "Update Gate: decides how much of new vs old info to keep.\n",
        "\n",
        "GRU is computationally lighter and trains faster than LSTM while still solving RNN shortcomings."
      ],
      "metadata": {
        "id": "hqaBOaSC5YUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#b)\tUse the emotions detection dataset from below Kaggle link and create an end-to-end project on Jupyter/Colab to predict the person’s emotions.\n",
        "\n",
        "https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp/data\n"
      ],
      "metadata": {
        "id": "ObUEl2oZ5dZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#i.\tDownload the dataset from above link and load it in your Python environment\n",
        "import zipfile, os\n",
        "\n",
        "# Path to uploaded file\n",
        "zip_path = \"/content/archive.zip\"\n",
        "extract_dir = \"/content/emotions_dataset\"\n",
        "\n",
        "# Extract zip\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(extract_dir)\n",
        "\n",
        "# List extracted files\n",
        "os.listdir(extract_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHLMLkzE5lLF",
        "outputId": "5018729e-6fdc-4bc0-c495-912657df3d75"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test.txt', 'train.txt', 'val.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#i.\tDownload the dataset from above link and load it in your Python environment\n",
        "import pandas as pd\n",
        "\n",
        "# Define paths\n",
        "train_path = os.path.join(extract_dir, \"train.txt\")\n",
        "val_path = os.path.join(extract_dir, \"val.txt\")\n",
        "test_path = os.path.join(extract_dir, \"test.txt\")\n",
        "\n",
        "# Load function\n",
        "def load_emotions_file(path):\n",
        "    return pd.read_csv(path, sep=\";\", header=None, names=[\"text\", \"emotion\"], encoding=\"utf-8\")\n",
        "\n",
        "# Load datasets\n",
        "train_df = load_emotions_file(train_path)\n",
        "val_df = load_emotions_file(val_path)\n",
        "test_df = load_emotions_file(test_path)\n",
        "\n",
        "(train_df.shape, val_df.shape, test_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjdLrxVNryhD",
        "outputId": "fa7ac250-b7bc-4d8b-a280-7af55036eb92"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16000, 2), (2000, 2), (2000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ii.    Perform the data cleaning like stopwords removal, lowercase, stemming, lemmatization etc.\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "# Download resources (only once, safe check)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab') # Added this line to download the missing resource\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "# Initialize tools\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs, mentions, special chars\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
        "    text = re.sub(r\"@\\w+|#\", '', text)\n",
        "    text = re.sub(r\"[^a-z\\s]\", '', text)\n",
        "    # Tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "    # Stemming + Lemmatization\n",
        "    tokens = [stemmer.stem(w) for w in tokens]\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply cleaning to train, val, and test datasets\n",
        "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
        "val_df[\"clean_text\"] = val_df[\"text\"].apply(clean_text)\n",
        "test_df[\"clean_text\"] = test_df[\"text\"].apply(clean_text)\n",
        "\n",
        "# Show samples\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "Dgt43zIps8WO",
        "outputId": "5a0ded24-bb11-4ad1-b6a4-da055ff5ea72"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  emotion  \\\n",
              "0                            i didnt feel humiliated  sadness   \n",
              "1  i can go from feeling so hopeless to so damned...  sadness   \n",
              "2   im grabbing a minute to post i feel greedy wrong    anger   \n",
              "3  i am ever feeling nostalgic about the fireplac...     love   \n",
              "4                               i am feeling grouchy    anger   \n",
              "\n",
              "                                          clean_text  \n",
              "0                                  didnt feel humili  \n",
              "1  go feel hopeless damn hope around someon care ...  \n",
              "2               im grab minut post feel greedi wrong  \n",
              "3     ever feel nostalg fireplac know still properti  \n",
              "4                                       feel grouchi  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b0e3070-6ae8-4d8a-99f8-d5a235001318\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "      <td>didnt feel humili</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>go feel hopeless damn hope around someon care ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "      <td>im grab minut post feel greedi wrong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "      <td>ever feel nostalg fireplac know still properti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "      <td>feel grouchi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b0e3070-6ae8-4d8a-99f8-d5a235001318')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b0e3070-6ae8-4d8a-99f8-d5a235001318 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b0e3070-6ae8-4d8a-99f8-d5a235001318');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3a614dfb-bad4-4c38-a975-cf1b2540c7b5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a614dfb-bad4-4c38-a975-cf1b2540c7b5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3a614dfb-bad4-4c38-a975-cf1b2540c7b5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 16000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15969,\n        \"samples\": [\n          \"i feel rather imbicilic or at least complacent\",\n          \"i was in the bathroom i had sat down to pee it was to make me feel submissive again per instructions\",\n          \"i am thrilled with the way my skin and hair feel if you are like me you are skeptical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"sadness\",\n          \"anger\",\n          \"joy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15854,\n        \"samples\": [\n          \"feel honor show student excit giardina said\",\n          \"stop feel lousi\",\n          \"realli badli wear anyth without caus spasm diarrhea eat mouth feel miser\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#iii.\tPerform feature engineering and word embedding techniques like TFIDF, word2Vec, Bag of words etc\n",
        "#Bag of Words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow_vectorizer = CountVectorizer(max_features=5000)  # choose vocabulary size\n",
        "X_train_bow = bow_vectorizer.fit_transform(train_df[\"clean_text\"])\n",
        "X_val_bow   = bow_vectorizer.transform(val_df[\"clean_text\"])\n",
        "X_test_bow  = bow_vectorizer.transform(test_df[\"clean_text\"])\n"
      ],
      "metadata": {
        "id": "IsCgmE7ctxT9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TFIDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"clean_text\"])\n",
        "X_val_tfidf   = tfidf_vectorizer.transform(val_df[\"clean_text\"])\n",
        "X_test_tfidf  = tfidf_vectorizer.transform(test_df[\"clean_text\"])\n"
      ],
      "metadata": {
        "id": "5918DeJzuLhb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "412bad86",
        "outputId": "04572235-3115-4744-8d9f-42de6e726c68"
      },
      "source": [
        "!pip install --upgrade numpy gensim"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.2)\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "Using cached gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Installing collected packages: numpy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.3\n",
            "    Uninstalling numpy-2.3.3:\n",
            "      Successfully uninstalled numpy-2.3.3\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.2\n",
            "    Uninstalling gensim-4.3.2:\n",
            "      Successfully uninstalled gensim-4.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "dbaf558d4afd4999a2b2a0d236b4e1ac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y gensim\n",
        "!pip install --no-cache-dir gensim==4.3.2\n",
        "!pip install --upgrade --force-reinstall numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "8oGWRDTR8WPB",
        "outputId": "2c6e8abf-8dc8-42fe-f53b-663050fe614c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: gensim 4.3.3\n",
            "Uninstalling gensim-4.3.3:\n",
            "  Successfully uninstalled gensim-4.3.3\n",
            "Collecting gensim==4.3.2\n",
            "  Downloading gensim-4.3.2.tar.gz (23.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.3/23.3 MB\u001b[0m \u001b[31m198.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim==4.3.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim==4.3.2) (1.13.1)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim==4.3.2) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim==4.3.2) (1.17.3)\n",
            "Building wheels for collected packages: gensim\n",
            "  Building wheel for gensim (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-4.3.2-cp312-cp312-linux_x86_64.whl size=26332387 sha256=f443658833a324b802b0b00f88461c4488e0db6fe46e6cb8f2648f4171ec1387\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vpfpzpf6/wheels/50/c0/ac/7bb08954bc59d390c848b480a3fc5eec68c14bc77bf334d624\n",
            "Successfully built gensim\n",
            "Installing collected packages: gensim\n",
            "Successfully installed gensim-4.3.2\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.3.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "c958fa4e934b493bbda082e74d2b47cc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word2vec\n",
        "\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Train Word2Vec on our training data (can also load pre-trained embeddings)\n",
        "sentences = [word_tokenize(text) for text in train_df[\"clean_text\"]]\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4)\n",
        "\n",
        "# Function to average word embeddings for a document\n",
        "def document_vector(doc):\n",
        "    words = [w for w in word_tokenize(doc) if w in w2v_model.wv]\n",
        "    if not words:\n",
        "        return np.zeros(100)\n",
        "    return np.mean(w2v_model.wv[words], axis=0)\n",
        "\n",
        "# Apply to train/val/test\n",
        "X_train_w2v = np.array([document_vector(text) for text in train_df[\"clean_text\"]])\n",
        "X_val_w2v   = np.array([document_vector(text) for text in val_df[\"clean_text\"]])\n",
        "X_test_w2v  = np.array([document_vector(text) for text in test_df[\"clean_text\"]])\n"
      ],
      "metadata": {
        "id": "Q-74GHla6xSq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iv.    Use the ML algorithms like logistic reg, DT, random forest etc. to predict the emotions.\n",
        "#Encode the target labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert emotion labels to numeric\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(train_df[\"emotion\"])\n",
        "y_val   = le.transform(val_df[\"emotion\"])\n",
        "y_test  = le.transform(test_df[\"emotion\"])\n",
        "\n",
        "\n",
        "#Train baseline ML models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_val, y_val, feature_name, model_name):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    results[f\"{model_name} ({feature_name})\"] = acc\n",
        "    print(f\"\\n{model_name} with {feature_name} features:\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(classification_report(y_val, y_pred, target_names=le.classes_))\n",
        "    return model\n",
        "\n",
        "# Logistic Regression with TF-IDF\n",
        "lr_tfidf = evaluate_model(\n",
        "    LogisticRegression(max_iter=200),\n",
        "    X_train_tfidf, y_train, X_val_tfidf, y_val,\n",
        "    \"TF-IDF\", \"Logistic Regression\"\n",
        ")\n",
        "\n",
        "# Decision Tree with TF-IDF\n",
        "dt_tfidf = evaluate_model(\n",
        "    DecisionTreeClassifier(),\n",
        "    X_train_tfidf, y_train, X_val_tfidf, y_val,\n",
        "    \"TF-IDF\", \"Decision Tree\"\n",
        ")\n",
        "\n",
        "# Random Forest with TF-IDF\n",
        "rf_tfidf = evaluate_model(\n",
        "    RandomForestClassifier(n_estimators=100),\n",
        "    X_train_tfidf, y_train, X_val_tfidf, y_val,\n",
        "    \"TF-IDF\", \"Random Forest\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv3-DKWiu04q",
        "outputId": "539053ea-2dfe-4759-ada6-cba18237d7c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression with TF-IDF features:\n",
            "Accuracy: 0.8705\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.90      0.84      0.87       275\n",
            "        fear       0.88      0.78      0.83       212\n",
            "         joy       0.86      0.94      0.90       704\n",
            "        love       0.86      0.65      0.74       178\n",
            "     sadness       0.88      0.93      0.90       550\n",
            "    surprise       0.86      0.63      0.73        81\n",
            "\n",
            "    accuracy                           0.87      2000\n",
            "   macro avg       0.87      0.80      0.83      2000\n",
            "weighted avg       0.87      0.87      0.87      2000\n",
            "\n",
            "\n",
            "Decision Tree with TF-IDF features:\n",
            "Accuracy: 0.826\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.81      0.81      0.81       275\n",
            "        fear       0.78      0.84      0.81       212\n",
            "         joy       0.85      0.83      0.84       704\n",
            "        love       0.73      0.70      0.71       178\n",
            "     sadness       0.86      0.88      0.87       550\n",
            "    surprise       0.72      0.72      0.72        81\n",
            "\n",
            "    accuracy                           0.83      2000\n",
            "   macro avg       0.79      0.80      0.79      2000\n",
            "weighted avg       0.83      0.83      0.83      2000\n",
            "\n",
            "\n",
            "Random Forest with TF-IDF features:\n",
            "Accuracy: 0.8635\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.85      0.88      0.87       275\n",
            "        fear       0.81      0.86      0.84       212\n",
            "         joy       0.89      0.86      0.88       704\n",
            "        love       0.79      0.71      0.75       178\n",
            "     sadness       0.89      0.93      0.91       550\n",
            "    surprise       0.76      0.77      0.76        81\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.83      0.83      0.83      2000\n",
            "weighted avg       0.86      0.86      0.86      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare performances across embeddings\n",
        "# Logistic Regression with Word2Vec\n",
        "lr_w2v = evaluate_model(\n",
        "    LogisticRegression(max_iter=200),\n",
        "    X_train_w2v, y_train, X_val_w2v, y_val,\n",
        "    \"Word2Vec\", \"Logistic Regression\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OHBItmQvd0b",
        "outputId": "94df8ba4-d4b5-40b0-87a7-c91d4ace559b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression with Word2Vec features:\n",
            "Accuracy: 0.372\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.00      0.00      0.00       275\n",
            "        fear       0.00      0.00      0.00       212\n",
            "         joy       0.38      0.81      0.52       704\n",
            "        love       0.00      0.00      0.00       178\n",
            "     sadness       0.35      0.32      0.33       550\n",
            "    surprise       0.00      0.00      0.00        81\n",
            "\n",
            "    accuracy                           0.37      2000\n",
            "   macro avg       0.12      0.19      0.14      2000\n",
            "weighted avg       0.23      0.37      0.27      2000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#View results in a table\n",
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame(list(results.items()), columns=[\"Model\", \"Validation Accuracy\"])\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDU0Ozmivinj",
        "outputId": "86bc29e2-ede5-4a6c-e037-86bc1e6cf4b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            Model  Validation Accuracy\n",
            "0    Logistic Regression (TF-IDF)               0.8705\n",
            "1          Decision Tree (TF-IDF)               0.8260\n",
            "2          Random Forest (TF-IDF)               0.8635\n",
            "3  Logistic Regression (Word2Vec)               0.3720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#v.     Do the hyperparameter tuning to get the best model.\n",
        "#logistic Regression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "grid_lr = GridSearchCV(\n",
        "    LogisticRegression(max_iter=500),\n",
        "    param_grid=param_grid_lr,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_lr.fit(X_train_tfidf, y_train)\n",
        "\n",
        "best_lr = grid_lr.best_estimator_\n",
        "print(\"Best Logistic Regression:\", grid_lr.best_params_)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, best_lr.predict(X_val_tfidf)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXnedhZ0vplJ",
        "outputId": "bb0a6218-6505-45ec-f583-5ddb350411b2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Logistic Regression: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Validation Accuracy: 0.8845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "param_grid_dt = {\n",
        "    'max_depth': [10, 20, 50, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "grid_dt = GridSearchCV(\n",
        "    DecisionTreeClassifier(),\n",
        "    param_grid=param_grid_dt,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_dt.fit(X_train_tfidf, y_train)\n",
        "\n",
        "best_dt = grid_dt.best_estimator_\n",
        "print(\"Best Decision Tree:\", grid_dt.best_params_)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, best_dt.predict(X_val_tfidf)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRYE8At_9wKn",
        "outputId": "e6ea966f-40a7-4748-b86d-801badfc4c50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Decision Tree: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5}\n",
            "Validation Accuracy: 0.8265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(\n",
        "    RandomForestClassifier(),\n",
        "    param_grid=param_grid_rf,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_rf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "best_rf = grid_rf.best_estimator_\n",
        "print(\"Best Random Forest:\", grid_rf.best_params_)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, best_rf.predict(X_val_tfidf)))\n"
      ],
      "metadata": {
        "id": "IaZPiibo93qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vi.\tFinally create a table to compare the performances of all the models and suggest the best model.\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Collect results\n",
        "results = []\n",
        "\n",
        "# Logistic Regression (TF-IDF)\n",
        "acc_lr_tfidf = accuracy_score(y_val, best_lr.predict(X_val_tfidf))\n",
        "results.append([\"Logistic Regression\", \"TF-IDF\", acc_lr_tfidf])\n",
        "\n",
        "# Decision Tree (TF-IDF)\n",
        "acc_dt_tfidf = accuracy_score(y_val, best_dt.predict(X_val_tfidf))\n",
        "results.append([\"Decision Tree\", \"TF-IDF\", acc_dt_tfidf])\n",
        "\n",
        "# Random Forest (TF-IDF)\n",
        "acc_rf_tfidf = accuracy_score(y_val, best_rf.predict(X_val_tfidf))\n",
        "results.append([\"Random Forest\", \"TF-IDF\", acc_rf_tfidf])\n",
        "\n",
        "# Create dataframe\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"Feature Type\", \"Validation Accuracy\"])\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "7dUaWQm3-I6e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}